# GPT Automation Examples

This document provides practical examples of using the GPT-powered automation features in fpf-sync.

## Prerequisites

1. OpenAI API key added as `OPENAI_API_KEY` secret in repository settings
2. GitHub Actions workflow permissions enabled
3. Bun installed (for local testing)

## Example 1: Automatic PR Review

When a pull request is created or updated, the GPT Code Review workflow automatically runs.

### What happens:
1. Workflow detects PR event (open, synchronize, or reopen)
2. Fetches PR details and code changes
3. Sends diff to GPT-4o-mini for analysis
4. Posts review comment on the PR

### Sample output:
```markdown
## ü§ñ GPT Code Review

### üìä Overall Assessment
The changes introduce a new GPT-powered code review feature with well-structured 
TypeScript code. The implementation follows best practices for GitHub Actions 
integration and includes comprehensive error handling.

### ‚úÖ Strengths
- Clear separation of concerns with modular functions
- Comprehensive error handling and logging
- Type-safe TypeScript implementation
- Good documentation and comments

### ‚ö†Ô∏è Concerns
- Large diffs may be truncated, potentially missing important context
- No rate limiting implementation for OpenAI API calls
- API key validation only happens at runtime

### üí° Suggestions
- Add input validation for environment variables at startup
- Consider implementing retry logic for API failures
- Add unit tests for core functions
- Document token usage and cost implications

### üìù Detailed Comments
- ‚ÑπÔ∏è **scripts/gpt-code-review.ts** (line 45): Consider adding a timeout for API calls
- ‚ö†Ô∏è **scripts/gpt-code-review.ts** (line 120): Truncation logic could be improved with smart splitting

---
*This review was generated by GPT-4 and should be used as a supplementary tool to human code review.*
```

## Example 2: Manual Code Review

Review recent code changes manually.

### Steps:
1. Go to **Actions** tab
2. Select "GPT Task Automation"
3. Click "Run workflow"
4. Fill in:
   - **Task type**: `code_review`
   - **Target**: `HEAD~5..HEAD` (review last 5 commits)
   - **Additional context**: (optional) "Focus on security concerns"
5. Click "Run workflow"

### Expected result:
Workflow logs will contain a detailed GPT analysis of the code changes.

## Example 3: Documentation Review

Check if documentation is clear and complete.

### Steps:
1. Go to **Actions** tab
2. Select "GPT Task Automation"
3. Click "Run workflow"
4. Fill in:
   - **Task type**: `documentation_check`
   - **Target**: (leave empty to review all docs)
   - **Additional context**: "Check for completeness and clarity"
5. Click "Run workflow"

### Sample output:
```
ü§ñ GPT Task Runner

üìã Task: documentation_check
üìù Context: Check for completeness and clarity

üìö Checking documentation...

================================================================================
RESULT:
================================================================================
The documentation is generally well-structured and comprehensive. Here are some observations:

Strengths:
- Clear organization with logical sections
- Good use of examples and code snippets
- Comprehensive setup instructions
- Troubleshooting section is helpful

Areas for improvement:
1. Add more examples of common use cases
2. Include screenshots for UI-related setup steps
3. Add a glossary of terms for beginners
4. Consider adding a "Quick Start" section for impatient users
5. Some technical terms could use more explanation

Specific suggestions:
- In README.md: Add a "Features" section summarizing capabilities
- In DEVELOPERS.md: Add architecture diagrams
- In GPT-AUTOMATION.md: Include cost estimation examples
================================================================================

‚úÖ Task completed successfully!
```

## Example 4: Commit Analysis

Analyze commit patterns to identify trends.

### Steps:
1. Go to **Actions** tab
2. Select "GPT Task Automation"
3. Click "Run workflow"
4. Fill in:
   - **Task type**: `commit_analysis`
   - **Target**: `HEAD~20..HEAD` (analyze last 20 commits)
   - **Additional context**: "Focus on code quality trends"
5. Click "Run workflow"

### Sample output:
```
ü§ñ GPT Task Runner

üìã Task: commit_analysis
üéØ Target: HEAD~20..HEAD
üìù Context: Focus on code quality trends

üìä Analyzing commits...

================================================================================
RESULT:
================================================================================
Analysis of the last 20 commits:

Commit Patterns:
- 12 feature commits (60%)
- 5 bug fix commits (25%)
- 3 documentation commits (15%)

Key Observations:
1. High feature velocity - many new capabilities added
2. Good commit message hygiene - clear, descriptive messages
3. Regular documentation updates alongside code changes
4. Consistent use of conventional commit prefixes

Code Quality Trends:
- Steady addition of TypeScript files with proper typing
- Good separation of concerns (scripts organized by purpose)
- Increasing test coverage over time
- Security-focused changes (API key handling improvements)

Areas of Focus:
- Recent commits show emphasis on automation and AI integration
- Strong focus on developer experience (documentation, tooling)
- Iterative improvement of existing features

Recommendations:
1. Continue the pattern of documentation-alongside-code
2. Consider adding more unit tests as features stabilize
3. Great momentum on automation - keep it up!
================================================================================

‚úÖ Task completed successfully!
```

## Example 5: Issue Triage

Help prioritize and label an issue.

### Steps:
1. Go to **Actions** tab
2. Select "GPT Task Automation"
3. Click "Run workflow"
4. Fill in:
   - **Task type**: `issue_triage`
   - **Target**: `42` (issue number)
   - **Additional context**: (optional) "Suggest appropriate labels"
5. Click "Run workflow"

### Sample output:
```
ü§ñ GPT Task Runner

üìã Task: issue_triage
üéØ Target: 42

üè∑Ô∏è  Triaging issue...

================================================================================
RESULT:
================================================================================
Issue #42 Triage Analysis:

Title: "Add support for multiple OpenAI models"

Summary:
User requests ability to choose different GPT models for different tasks.

Suggested Labels:
- enhancement
- good first issue
- documentation needed

Priority: Medium

Rationale:
- This is a feature enhancement, not a bug
- Implementation is relatively straightforward (config option)
- Would improve flexibility and cost management
- Good opportunity for new contributors

Suggested Next Steps:
1. Clarify which models should be supported (gpt-4, gpt-4o, gpt-3.5-turbo)
2. Design configuration approach (env var, config file, per-task)
3. Update documentation with model selection guide
4. Consider cost implications and add warnings for expensive models
5. Add tests for model selection logic

Potential Blockers:
- None identified

Estimated Effort: Small (2-4 hours)

Additional Context:
This aligns well with the project's goal of leveraging OpenAI capabilities 
effectively. Consider adding model benchmarking to help users choose.
================================================================================

‚úÖ Task completed successfully!
```

## Example 6: Local Testing

Test the GPT scripts locally before running in GitHub Actions.

### Prerequisites:
```bash
export OPENAI_API_KEY="sk-..."
cd /home/runner/work/fpf-sync/fpf-sync
bun install
```

### Test code review:
```bash
# Review last 3 commits
export TASK_TYPE="code_review"
export TASK_TARGET="HEAD~3..HEAD"
bun run scripts/gpt-task-runner.ts
```

### Test documentation check:
```bash
export TASK_TYPE="documentation_check"
export TASK_TARGET=""
bun run scripts/gpt-task-runner.ts
```

### Test with mock PR (requires gh CLI):
```bash
# Create a test PR first, then:
export PR_NUMBER="123"
export GITHUB_TOKEN="ghp_..."
bun run scripts/gpt-code-review.ts
```

## Example 7: Customizing GPT Prompts

You can modify the prompts in the scripts to suit your needs.

### Location:
- `scripts/gpt-code-review.ts` - Line ~135 (review prompt)
- `scripts/gpt-task-runner.ts` - Various functions (task-specific prompts)

### Example customization:
```typescript
// In scripts/gpt-code-review.ts
const prompt = `Review the following pull request with emphasis on:
1. Security vulnerabilities
2. Performance optimizations
3. Code reusability
4. ${additionalFocus}  // Custom focus area

**Code Changes:**
...
`;
```

## Troubleshooting Examples

### Issue: Rate limit exceeded

**Error in logs:**
```
‚ùå Error during GPT review: Error: OpenAI API call failed: 429 Rate limit exceeded
```

**Solution:**
Wait a few minutes and re-run the workflow. If persistent:
1. Check your OpenAI rate limits: https://platform.openai.com/account/limits
2. Upgrade your OpenAI tier if needed
3. Add retry logic with exponential backoff

### Issue: API key not found

**Error in logs:**
```
‚ùå Missing required environment variable: OPENAI_API_KEY
```

**Solution:**
1. Verify secret exists: Settings ‚Üí Secrets and variables ‚Üí Actions
2. Ensure secret name is exactly `OPENAI_API_KEY`
3. Re-run the workflow after adding/fixing the secret

### Issue: No PR changes detected

**Output:**
```
‚ÑπÔ∏è  No code changes detected. Skipping review.
```

**Cause:**
PR has no code changes (might be only merge commits or conflicts).

**Solution:**
This is normal for empty PRs. No action needed.

## Best Practices

1. **Start small**: Test with single file changes before large refactors
2. **Review GPT output**: Don't blindly follow suggestions - use judgment
3. **Provide context**: Add PR descriptions to help GPT understand intent
4. **Monitor costs**: Keep track of API usage in OpenAI dashboard
5. **Iterate prompts**: Customize prompts based on your project's needs
6. **Combine with human review**: GPT is a tool, not a replacement

## Additional Resources

- [OpenAI API Documentation](https://platform.openai.com/docs)
- [GPT-4 Best Practices](https://platform.openai.com/docs/guides/gpt-best-practices)
- [GitHub Actions Documentation](https://docs.github.com/en/actions)
- [Main GPT Documentation](./GPT-AUTOMATION.md)
